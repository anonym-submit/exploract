{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd1ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pickle\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.data import Dataset\n",
    "from lib.utilities import Repository\n",
    "import traceback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4530fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repo = Repository('./session_repositories/actions.tsv','./session_repositories/displays.tsv','./raw_datasets/')\n",
    "\n",
    "with open(f'./edge/act_five_feats.pickle', 'rb') as fin:\n",
    "    act_feats = pickle.load(fin)\n",
    "\n",
    "with open(f'./edge/col_action.pickle', 'rb') as fin:\n",
    "    col_feats = pickle.load(fin)\n",
    "\n",
    "with open(f'./display_feats/display_pca_feats_{9999}.pickle', 'rb') as fin:\n",
    "    display_pca_feats = pickle.load(fin)\n",
    "\n",
    "num_col_classes = 0\n",
    "actcol_feats = {}\n",
    "for key in act_feats:\n",
    "    num_col_classes = len(col_feats[key])\n",
    "    feat = np.zeros(len(act_feats[key]) * len(col_feats[key]))\n",
    "    offset = np.argmax(act_feats[key]) * len(col_feats[key])\n",
    "    feat[offset + np.argmax(col_feats[key])] = 1\n",
    "    actcol_feats[key] = feat.copy()\n",
    "\n",
    "concat_feats = {}\n",
    "for key in act_feats:\n",
    "    concat_feats[key] = np.concatenate((act_feats[key], col_feats[key])).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf4d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predecessors(G, node):\n",
    "    predecessors = []\n",
    "    for v in G.neighbors(node):\n",
    "        if v < node:\n",
    "            predecessors.append(v)\n",
    "    return predecessors\n",
    "\n",
    "def get_successors(G, node):\n",
    "    successors = []\n",
    "    for v in G.neighbors(node):\n",
    "        if v > node:\n",
    "            successors.append(v)\n",
    "    return successors\n",
    "\n",
    "def bfs(G, root):\n",
    "    depth = 0\n",
    "    node_count_at_depth = {}\n",
    "    nodes_at_depth = {}\n",
    "    successors = [root]\n",
    "    traversal = []\n",
    "    while len(successors) > 0:\n",
    "        # successors.sort()\n",
    "        traversal.extend(successors)\n",
    "        nodes_at_depth[depth] = []\n",
    "        next_level = []\n",
    "        for v in successors:\n",
    "            nodes_at_depth[depth].append(v)\n",
    "            next_level.extend(get_successors(G, v))\n",
    "\n",
    "        node_count_at_depth[depth] = len(successors)\n",
    "        depth += 1\n",
    "\n",
    "        successors = next_level\n",
    "\n",
    "    return traversal, node_count_at_depth, nodes_at_depth\n",
    "\n",
    "def dfs(G, root):\n",
    "    successors = get_successors(G, root)\n",
    "    if len(successors) == 0:\n",
    "        return [root]\n",
    "    successors.sort()\n",
    "    traversal = [root]\n",
    "    for v in successors:\n",
    "        v_traversal = dfs(G, v)\n",
    "        traversal += v_traversal\n",
    "\n",
    "    return traversal\n",
    "\n",
    "def replay_graph(edges, d_feats, a_feats, tar, sizes, main_size, is_train):\n",
    "    logic_error_displays = [427, 428, 429, 430, \n",
    "                        854, 855, 856, 868, 891, \n",
    "                        977, 978, 979, 980, \n",
    "                        1304, 1908, 1909, 1983, \n",
    "                        2022, 2023, 2024, 2195,\n",
    "                        3244, 3446, 3447, \n",
    "                        4050, 4051, 4056, 4052, 4054, 4055, 4057, 4058, 4059, \n",
    "                        4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067]\n",
    "\n",
    "    replays = []\n",
    "    display_seqs = []\n",
    "    action_seqs = []\n",
    "    y = []\n",
    "    end_aids = []\n",
    "\n",
    "    try:\n",
    "        BigG = nx.from_edgelist(edges, create_using=nx.Graph)\n",
    "        S = [BigG.subgraph(c).copy() for c in nx.connected_components(BigG)]\n",
    "\n",
    "        # context = size\n",
    "        for G in S:\n",
    "            g_nodes = list(G.nodes())\n",
    "            g_nodes.sort()\n",
    "            g_nodes.reverse()\n",
    "            for end in G.nodes():\n",
    "                if end in logic_error_displays:\n",
    "                    continue\n",
    "                \n",
    "                leading_to_end = None\n",
    "                max_context = 0\n",
    "                primary_nodes = None\n",
    "                cxts = []\n",
    "                for context in sizes:\n",
    "                    tree_nodes = set()\n",
    "                    for v in g_nodes:\n",
    "                        if v < end and len(tree_nodes) < context:\n",
    "                            tree_nodes.add(v)\n",
    "\n",
    "                    if len(tree_nodes) > max_context:\n",
    "                        max_context = len(tree_nodes)\n",
    "                        primary_nodes = list(tree_nodes)\n",
    "\n",
    "                    if len(tree_nodes) < context:\n",
    "                        break\n",
    "\n",
    "                    leading_to_end = get_predecessors(G, end)[0]\n",
    "                    \n",
    "                    tree_nodes_list = list(tree_nodes)\n",
    "                    backtracks = []\n",
    "                    max_path_length = 0\n",
    "                    max_path_index = 0\n",
    "                    for j in range(len(tree_nodes)):\n",
    "                        v = tree_nodes_list[j]\n",
    "                        predecessors = get_predecessors(G, v)\n",
    "                        path = [v]\n",
    "                        while len(predecessors) > 0:\n",
    "                            path.append(predecessors[0])\n",
    "                            predecessors = get_predecessors(G, predecessors[0])\n",
    "                        \n",
    "                        if len(path) > max_path_length:\n",
    "                            max_path_length = len(path)\n",
    "                            max_path_index = j\n",
    "                        \n",
    "                        path.reverse()\n",
    "                        backtracks.append(path)\n",
    "                    \n",
    "                    proceed = True\n",
    "                    i = -1\n",
    "                    while proceed:\n",
    "                        i += 1\n",
    "                        if i >= max_path_length:\n",
    "                            break\n",
    "\n",
    "                        match_value = backtracks[max_path_index][i]\n",
    "                        for path in backtracks:\n",
    "                            if len(path) <= i:\n",
    "                                proceed = False\n",
    "                                break\n",
    "                            if match_value != path[i]:\n",
    "                                proceed = False\n",
    "                                break\n",
    "                        \n",
    "                    for path in backtracks:\n",
    "                        for v in path[i-1:]:\n",
    "                            tree_nodes.add(v)\n",
    "\n",
    "                    g_context = nx.induced_subgraph(G, tree_nodes).copy()\n",
    "\n",
    "                    root = None\n",
    "                    for v in g_context.nodes():\n",
    "                        if len(get_predecessors(g_context, v)) == 0:\n",
    "                            root = v\n",
    "\n",
    "                    node_order, node_count_at_depth, nodes_at_depth = bfs(g_context, root)\n",
    "\n",
    "                    node_depth = {}\n",
    "                    for depth in nodes_at_depth:\n",
    "                        depth_nodes = nodes_at_depth[depth]\n",
    "                        depth_nodes.sort()\n",
    "                        for i in range(len(depth_nodes)):\n",
    "                            v = depth_nodes[i]\n",
    "                            node_depth[v] = (depth, i)\n",
    "\n",
    "                    tree_nodes = list(tree_nodes)\n",
    "                    tree_nodes.sort()\n",
    "                    attrs = {}\n",
    "                    for i in range(len(tree_nodes)):\n",
    "                        v = tree_nodes[i]\n",
    "                        v_feat = d_feats[v]\n",
    "                        attrs[v] = {\"x\":v_feat.astype(np.float32), \"pos\":node_depth[v]}\n",
    "                    nx.set_node_attributes(g_context, attrs)\n",
    "\n",
    "                    attrs = {}\n",
    "                    for edge in g_context.edges():\n",
    "                        e_feat = a_feats[g_context.edges[edge[0], edge[1]]['aid']]\n",
    "                        attrs[(edge[0], edge[1])] = {\"x\":e_feat.astype(np.float32)}\n",
    "                    nx.set_edge_attributes(g_context, attrs)\n",
    "\n",
    "                    cxts.append(g_context)\n",
    "\n",
    "                if len(cxts) == len(sizes):\n",
    "                    end_aid = G.edges[leading_to_end, end]['aid']\n",
    "                    replays.append(cxts)\n",
    "                    end_aids.append(end_aid)\n",
    "\n",
    "                    if is_train:\n",
    "                        target_act = tar[0][end_aid]\n",
    "                        target_col = tar[1][end_aid]\n",
    "                        target_tg = tar[2][end_aid]\n",
    "                    else:\n",
    "                        target_act = np.argmax(tar[0][end_aid])\n",
    "                        target_col = np.argmax(tar[1][end_aid])\n",
    "                        target_tg = np.argmax(tar[2][end_aid])\n",
    "                    y.append([target_act, target_col, target_tg])\n",
    "\n",
    "                    ### SEQUENCE STUFF ###\n",
    "                    assert max_context == main_size\n",
    "                    primary_nodes.sort()\n",
    "                    main_g_context = cxts[0]\n",
    "                    action_sequence = []\n",
    "                    for v in primary_nodes[1:]:\n",
    "                        u = get_predecessors(main_g_context, v)[0]\n",
    "                        action_sequence.append(main_g_context.edges[u, v]['x'])\n",
    "                    \n",
    "                    display_sequence = []\n",
    "                    for v in primary_nodes:\n",
    "                        display_sequence.append(main_g_context.nodes[v]['x'])\n",
    "                    \n",
    "                    action_seqs.append(torch.tensor(np.array(action_sequence), dtype=torch.float32))\n",
    "                    display_seqs.append(torch.tensor(np.array(display_sequence), dtype=torch.float32))\n",
    "                \n",
    "    except Exception as e:\n",
    "        # print(g_context.edges.data())\n",
    "        # print(traceback.format_exc())\n",
    "        print()\n",
    "\n",
    "    return replays, action_seqs, display_seqs, y, end_aids\n",
    "\n",
    "\n",
    "def generate_sessions(repo):\n",
    "    og_columns = ['captured_length', 'length', 'tcp_stream', 'number', 'eth_dst', 'eth_src', \n",
    "                'highest_layer', 'info_line', 'interface_captured', 'ip_dst', 'ip_src', 'sniff_timestamp', 'tcp_dstport', 'tcp_srcport']\n",
    "    sessions = {}\n",
    "    for project_id in range(1, 5):\n",
    "        my_sessions = []\n",
    "        for session_id in repo.actions[repo.actions['project_id'] == project_id]['session_id'].unique():\n",
    "            nodes = set()\n",
    "            edges = []\n",
    "            unrelated = False\n",
    "            for i, row in repo.actions[repo.actions['session_id'] == session_id][['action_id', 'action_type', 'action_params', 'parent_display_id', 'child_display_id', 'solution']].iterrows():\n",
    "                solution = 1 if row['solution'] else 0\n",
    "                u = int(row['parent_display_id'])\n",
    "                v = int(row['child_display_id'])\n",
    "                aid = int(row['action_id'])\n",
    "\n",
    "                nodes.add(u)\n",
    "                nodes.add(v)\n",
    "\n",
    "                if row['action_type'] == 'sort' and (not bool(row['action_params'])):\n",
    "                    check_col = 'number'\n",
    "                    row['action_params']['field'] = 'number'\n",
    "                else:\n",
    "                    check_col = row['action_params']['field']\n",
    "\n",
    "                if not check_col in og_columns:\n",
    "                    unrelated = True\n",
    "\n",
    "                edges.append([u, v, {'aid':aid}])\n",
    "\n",
    "            if not unrelated:\n",
    "                my_sessions.append(edges)\n",
    "\n",
    "        sessions[project_id] = my_sessions\n",
    "    \n",
    "    return sessions\n",
    "\n",
    "\n",
    "def treefy_sessions(sessions, d_feats, a_feats, tar, sizes, main_size, test_id):\n",
    "    test_contexts = []\n",
    "    test_act_seqs = []\n",
    "    test_display_seqs = []\n",
    "    test_y = []\n",
    "    test_aids = []\n",
    "    train_contexts = []\n",
    "    train_act_seqs = []\n",
    "    train_display_seqs = []\n",
    "    train_y = []\n",
    "    train_aids = []\n",
    "    for chunk_id in sessions:\n",
    "        if chunk_id in test_id:\n",
    "            for edges in sessions[chunk_id]:\n",
    "                g_contexts, act_seqs, display_seqs, g_ys, end_aids = replay_graph(edges, d_feats, a_feats, tar, sizes=sizes, main_size=main_size, is_train=False)\n",
    "                test_contexts.extend(g_contexts)\n",
    "                test_act_seqs.extend(act_seqs)\n",
    "                test_display_seqs.extend(display_seqs)\n",
    "                test_y.extend(g_ys)\n",
    "                test_aids.extend(end_aids)\n",
    "        else:\n",
    "            for edges in sessions[chunk_id]:\n",
    "                g_contexts, act_seqs, display_seqs, g_ys, end_aids = replay_graph(edges, d_feats, a_feats, tar, sizes=sizes, main_size=main_size, is_train=True)\n",
    "                train_contexts.extend(g_contexts)\n",
    "                train_act_seqs.extend(act_seqs)\n",
    "                train_display_seqs.extend(display_seqs)\n",
    "                train_y.extend(g_ys)\n",
    "                train_aids.extend(end_aids)\n",
    "\n",
    "    return train_contexts, train_act_seqs, train_display_seqs, train_y, train_aids, test_contexts, test_act_seqs, test_display_seqs, test_y, test_aids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2da4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqTestDataset(Dataset):\n",
    "    def __init__(self, seqs, lumps, ys):\n",
    "        super(SeqTestDataset, self).__init__()\n",
    "        self.seqs = seqs\n",
    "        self.lumps = lumps\n",
    "        self.ys = ys\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.seqs)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        lump = self.lumps[idx]\n",
    "        return seq, lump, torch.tensor(self.ys[idx], dtype=torch.long)\n",
    "\n",
    "def strip_graph_attributes(graph):\n",
    "    for (_, d) in graph.nodes(data=True):\n",
    "        del d['pos']\n",
    "    for (_, _, d) in graph.edges(data=True):\n",
    "        del d['aid']\n",
    "\n",
    "def class_seperation(y):\n",
    "    classes = {}\n",
    "    for c in set(y):\n",
    "        classes[c] = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        classes[y[i]].append(i)\n",
    "\n",
    "    return classes\n",
    "    \n",
    "def make_directed(graph_sets):\n",
    "    directed_graphs = []\n",
    "    for graphs in graph_sets:\n",
    "        curr_set = []\n",
    "        for i in range(len(graphs)):\n",
    "            graph = graphs[i]\n",
    "            if graph is None:\n",
    "                curr_set.append(None)\n",
    "            else:\n",
    "                strip_graph_attributes(graph)\n",
    "                dg = graph.to_directed()\n",
    "                to_remove = []\n",
    "                for edge in dg.edges():\n",
    "                    if edge[0] > edge[1]:\n",
    "                        to_remove.append(edge)\n",
    "\n",
    "                dg.remove_edges_from(to_remove)\n",
    "                pyg = from_networkx(dg)\n",
    "                if graph.number_of_nodes() == 1:\n",
    "                    pyg.edge_x = torch.empty((0, 20), dtype=torch.float)\n",
    "                \n",
    "                curr_set.append(pyg)\n",
    "                \n",
    "        directed_graphs.append(curr_set)\n",
    "\n",
    "    return directed_graphs\n",
    "\n",
    "def generate_lump_graphs(graph_sets, classes):\n",
    "    lump_graphs = {}\n",
    "    for c in classes:\n",
    "        pos_feats = {}\n",
    "        for i in classes[c]:\n",
    "            for graph in graph_sets[i]:\n",
    "                if graph is None:\n",
    "                    continue\n",
    "                for node in graph.nodes():\n",
    "                    pos = graph.nodes[node]['pos']\n",
    "                    if not (pos[0] in pos_feats):\n",
    "                        pos_feats[pos[0]] = {}\n",
    "                    if not (pos[1] in pos_feats[pos[0]]):\n",
    "                        pos_feats[pos[0]][pos[1]] = []\n",
    "                    pos_feats[pos[0]][pos[1]].append(graph.nodes[node]['x'])\n",
    "\n",
    "        pos_to_id_map = {}\n",
    "        pos_id = 0\n",
    "        for depth in pos_feats:\n",
    "            pos_to_id_map[depth] = {}\n",
    "            for order in pos_feats[depth]:\n",
    "                pos_feats[depth][order] = np.array(pos_feats[depth][order], dtype=np.float32).mean(axis=0)\n",
    "                pos_to_id_map[depth][order] = pos_id\n",
    "                pos_id += 1\n",
    "\n",
    "        pos_edge_feats = {}\n",
    "        for i in classes[c]:\n",
    "            for graph in graph_sets[i]:\n",
    "                if graph is None:\n",
    "                    continue\n",
    "                for edge in graph.edges():\n",
    "                    u = min(edge[0], edge[1])\n",
    "                    v = max(edge[0], edge[1])\n",
    "                    u_pos = graph.nodes[u]['pos']\n",
    "                    v_pos = graph.nodes[v]['pos']\n",
    "                    u_id = pos_to_id_map[u_pos[0]][u_pos[1]]\n",
    "                    v_id = pos_to_id_map[v_pos[0]][v_pos[1]]\n",
    "                    \n",
    "                    if not (u_id in pos_edge_feats):\n",
    "                        pos_edge_feats[u_id] = {}\n",
    "                    if not (v_id in pos_edge_feats[u_id]):\n",
    "                        pos_edge_feats[u_id][v_id] = []\n",
    "\n",
    "                    pos_edge_feats[u_id][v_id].append(graph.edges[edge[0], edge[1]]['x'])\n",
    "        \n",
    "        lump_graph_edges = []\n",
    "        for u_id in pos_edge_feats:\n",
    "            for v_id in pos_edge_feats[u_id]:\n",
    "                pos_edge_feats[u_id][v_id] = np.array(pos_edge_feats[u_id][v_id], dtype=np.float32).mean(axis=0)\n",
    "                lump_graph_edges.append((u_id, v_id, {\"x\":pos_edge_feats[u_id][v_id]}))\n",
    "\n",
    "        node_attrs = {}\n",
    "        for depth in pos_feats:\n",
    "            for order in pos_feats[depth]:\n",
    "                node_attrs[pos_to_id_map[depth][order]] = {\"x\":pos_feats[depth][order]}\n",
    "                # node_attrs[pos_to_id_map[depth][order]] = {\"x\":pos_feats[depth][order], \"pos\":(depth, order)}\n",
    "        \n",
    "        lump_g = nx.from_edgelist(lump_graph_edges, create_using=nx.DiGraph)\n",
    "        nx.set_node_attributes(lump_g, node_attrs)\n",
    "\n",
    "        lump_graphs[c] = lump_g\n",
    "\n",
    "    return lump_graphs\n",
    "\n",
    "def generate_test_pairs(graph_set, y, lump_graphs):\n",
    "    graph_sets_new = []\n",
    "    lumps = []\n",
    "    labels = []\n",
    "    for c in lump_graphs:\n",
    "        # graph_set.reverse()\n",
    "        graph_sets_new.append(graph_set)\n",
    "        lumps.append(from_networkx(lump_graphs[c]))\n",
    "        labels.append(c)\n",
    "    \n",
    "    return graph_sets_new, lumps, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299c7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_naive(act_probs, col_probs, tg_probs, classes, test_y, k):\n",
    "    preds = []\n",
    "    for m in range(len(test_y)):\n",
    "        test_case = [0] * len(tg_probs[m])\n",
    "        for i, act_prob in enumerate(act_probs[m]):\n",
    "            act_cls = classes['act'][i]\n",
    "            for j, col_prob in enumerate(col_probs[m]):\n",
    "                col_cls = classes['col'][j]\n",
    "                actcol_mass = act_prob * col_prob\n",
    "                for n, tg_mass in enumerate(tg_probs[m]):\n",
    "                    tgd_cls = classes['tgd'][n]\n",
    "                    tgd_act, tgd_col = tgd_cls[0], tgd_cls[1]\n",
    "                    if act_cls == tgd_act and col_cls == tgd_col:\n",
    "                        test_case[n] += actcol_mass * tg_mass\n",
    "\n",
    "        indices = torch.topk(torch.tensor(test_case, dtype=torch.float32), k, dim=0).indices.tolist()\n",
    "        preds.append(classes['tg'][indices].tolist())\n",
    "        \n",
    "    corrects = [0] * len(test_y)\n",
    "    mrrs = [0] * len(test_y)\n",
    "    total = 0\n",
    "    for i in range(len(test_y)):\n",
    "        total += 1\n",
    "        for j in range(len(preds[i])):\n",
    "            if test_y[i][2] == preds[i][j]:\n",
    "                corrects[i] = 1\n",
    "                mrrs[i] = 1 / (j + 1)\n",
    "    \n",
    "    correct = sum(corrects)\n",
    "    mrr = sum(mrrs)\n",
    "    acc = round(correct / total, 4)\n",
    "    mrr_acc = round(mrr / total, 4) \n",
    "\n",
    "    return acc, mrr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c192c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dst(act_probs, col_probs, tg_probs, classes, test_y, k):\n",
    "    preds = []\n",
    "    for m in range(len(test_y)):\n",
    "        test_case = [0] * len(tg_probs[m])\n",
    "        K = 0\n",
    "        for i, act_prob in enumerate(act_probs[m]):\n",
    "            act_cls = classes['act'][i]\n",
    "            for j, col_prob in enumerate(col_probs[m]):\n",
    "                col_cls = classes['col'][j]\n",
    "                actcol_mass = act_prob * col_prob\n",
    "                for n, tg_mass in enumerate(tg_probs[m]):\n",
    "                    tgd_cls = classes['tgd'][n]\n",
    "                    tgd_act, tgd_col = tgd_cls[0], tgd_cls[1]\n",
    "                    if act_cls != tgd_act or col_cls != tgd_col:\n",
    "                        K += actcol_mass * tg_mass\n",
    "                    else:\n",
    "                        test_case[n] += actcol_mass * tg_mass\n",
    "\n",
    "        for n in range(len(test_case)):\n",
    "            test_case[n] = test_case[n] / (1 - K)\n",
    "\n",
    "        indices = torch.topk(torch.tensor(test_case, dtype=torch.float32), k, dim=0).indices.tolist()\n",
    "        preds.append(classes['tg'][indices].tolist())\n",
    "        \n",
    "    corrects = [0] * len(test_y)\n",
    "    mrrs = [0] * len(test_y)\n",
    "    total = 0\n",
    "    for i in range(len(test_y)):\n",
    "        total += 1\n",
    "        for j in range(len(preds[i])):\n",
    "            if test_y[i][2] == preds[i][j]:\n",
    "                corrects[i] = 1\n",
    "                mrrs[i] = 1 / (j + 1)\n",
    "    \n",
    "    correct = sum(corrects)\n",
    "    mrr = sum(mrrs)\n",
    "    acc = round(correct / total, 4)\n",
    "    mrr_acc = round(mrr / total, 4) \n",
    "\n",
    "    return acc, mrr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07eca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "& \\begin{tabular}[c]{@{}l@{}}$.48_{.04}$\\\\ $.33_{.03}$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$.44_{.04}$\\\\ $.31_{.03}$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$.43_{.06}$\\\\ $.30_{.03}$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$.42_{.06}$\\\\ $.28_{.04}$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$.39_{.07}$\\\\ $.27_{.04}$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$.40_{.04}$\\\\ $.27_{.03}$\\end{tabular} &\n",
      "\n",
      "Min=7.72, 8.54 | Max=20.94, 13.87 Avg=13.691666666666666, 11.548333333333332\n",
      "Min=10.62, 7.52 Max=20.73, 31.53\n",
      "\n",
      "& \\begin{tabular}[c]{@{}l@{}}$12.95\\%$\\\\ $11.51\\%$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$10.88\\%$\\\\ $13.2\\%$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$7.72\\%$\\\\ $9.13\\%$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$12.9\\%$\\\\ $8.54\\%$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$20.94\\%$\\\\ $13.87\\%$\\end{tabular} &\n",
      " \\begin{tabular}[c]{@{}l@{}}$16.76\\%$\\\\ $13.04\\%$\\end{tabular} &\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seed = 20250212\n",
    "# test_id = [4]\n",
    "\n",
    "file_fix = \"own\" # 'own'=EF-MP | 'seq'=EF-SP\n",
    "\n",
    "tar_feats = [act_feats, col_feats, actcol_feats]\n",
    "\n",
    "ra3_gains_react = []\n",
    "mrr_gains_react = []\n",
    "ra3_gains_noef = []\n",
    "mrr_gains_noef = []\n",
    "\n",
    "entry = \"&\"\n",
    "gain_entry = \"&\"\n",
    "\n",
    "for main_size in range(3, 9):\n",
    "    sizes = list(range(1, main_size + 1))\n",
    "    sizes.reverse()\n",
    "\n",
    "    overall_ra3 = {'react':[], 'ours':[], 'dst':[]}\n",
    "    overall_mrr = {'react':[], 'ours':[], 'dst':[]}\n",
    "\n",
    "    for seed in [20250212, 20250214, 20250314]:\n",
    "        chunked_sessions = pickle.load(open(f'./chunked_sessions/unbiased_seed_{seed}.pickle', 'rb'))\n",
    "        for tid in range(5):\n",
    "            test_id = [tid]\n",
    "\n",
    "            train_x, train_act_seqs, train_display_seqs, train_y, train_aids, test_x, test_act_seqs, test_display_seqs, test_y, test_aids = treefy_sessions(\n",
    "                                                                                                                                                sessions=chunked_sessions, \n",
    "                                                                                                                                                d_feats=display_pca_feats, \n",
    "                                                                                                                                                a_feats=concat_feats,\n",
    "                                                                                                                                                tar=tar_feats, \n",
    "                                                                                                                                                sizes=sizes, \n",
    "                                                                                                                                                main_size=main_size,\n",
    "                                                                                                                                                test_id=test_id\n",
    "                                                                                                                                            )\n",
    "            # print(len(train_y), len(test_y))\n",
    "\n",
    "            lump_graphs = {}\n",
    "            for j, task in enumerate(['act', 'col', 'tg']):\n",
    "                non_hot_train_y = [int(np.argmax(train_y[i][j])) for i in range(len(train_y))]\n",
    "                train_classes = class_seperation(non_hot_train_y)\n",
    "                lump_graphs[task] = generate_lump_graphs(train_x, train_classes)\n",
    "\n",
    "            train_x = make_directed(train_x)\n",
    "            test_x = make_directed(test_x)\n",
    "\n",
    "            classes = {}\n",
    "            for task in ['act', 'col', 'tg']:\n",
    "                clss = []\n",
    "                for c in lump_graphs[task]:\n",
    "                    clss.append(c)\n",
    "                classes[task] = clss\n",
    "\n",
    "            clss = []\n",
    "            for c in classes['tg']:\n",
    "                clss.append([math.floor(c / num_col_classes), c % num_col_classes])\n",
    "            classes['tgd'] = clss\n",
    "            classes['tg'] = torch.tensor(classes['tg'], dtype=torch.long)\n",
    "\n",
    "            act_prob = pickle.load(open(f'./dst_probs/gine_{file_fix}_act_best_ra3_{seed}_{test_id}_{main_size}.pickle', 'rb'))\n",
    "            col_prob = pickle.load(open(f'./dst_probs/gine_{file_fix}_col_best_ra3_{seed}_{test_id}_{main_size}.pickle', 'rb'))\n",
    "            tg_prob = pickle.load(open(f'./dst_probs/gine_{file_fix}_tg_best_ra3_{seed}_{test_id}_{main_size}.pickle', 'rb'))\n",
    "\n",
    "            # dst_ra3, dst_mrr = apply_dst(act_prob, col_prob, tg_prob, classes, test_y, 3)\n",
    "            dst_ra3, dst_mrr = apply_naive(act_prob, col_prob, tg_prob, classes, test_y, 3)\n",
    "            overall_ra3['dst'].append(dst_ra3)\n",
    "            overall_mrr['dst'].append(dst_mrr)\n",
    "\n",
    "            res = pickle.load(open(f'./chunk_ted_results/{seed}_{main_size}_{tid}_unbiased.pickle', 'rb'))\n",
    "            overall_ra3['react'].append(res['ra3'][2])\n",
    "            overall_mrr['react'].append(res['mrr'][2])\n",
    "\n",
    "            res = pickle.load(open(f'./model_stats/tg_{seed}_{main_size}_[{tid}]_gine_{file_fix}.pickle', 'rb'))\n",
    "            overall_ra3['ours'].extend(res['ra3'])\n",
    "            overall_mrr['ours'].extend(res['mrr'])\n",
    "\n",
    "    react_ra3, ours_ra3, dst_ra3 = statistics.mean(overall_ra3['react']), statistics.mean(overall_ra3['ours']), statistics.mean(overall_ra3['dst'])\n",
    "    ra3_gain_react = round(((dst_ra3 - react_ra3) / react_ra3) * 100, 2)\n",
    "    ra3_gain_noef = round(((dst_ra3 - ours_ra3) / ours_ra3) * 100, 2)\n",
    "    react_mrr, ours_mrr, dst_mrr = statistics.mean(overall_mrr['react']), statistics.mean(overall_mrr['ours']), statistics.mean(overall_mrr['dst'])\n",
    "    mrr_gain_react = round(((dst_mrr - react_mrr) / react_mrr) * 100, 2)\n",
    "    mrr_gain_noef = round(((dst_mrr - ours_mrr) / ours_mrr) * 100, 2)\n",
    "\n",
    "    ra3_gains_react.append(ra3_gain_react)\n",
    "    mrr_gains_react.append(mrr_gain_react)\n",
    "\n",
    "    ra3_gains_noef.append(ra3_gain_noef)\n",
    "    mrr_gains_noef.append(mrr_gain_noef)\n",
    "\n",
    "    # print(f'------------------{seed}-{main_size}-------------------')\n",
    "    # print(round(react_ra3, 2), round(ours_ra3, 2), round(dst_ra3, 2), f'{ra3_gain}%')\n",
    "    # print(round(react_mrr, 2), round(ours_mrr, 2), round(dst_mrr, 2), f'{mrr_gain}%')\n",
    "\n",
    "    dst_ra3 = int(round(dst_ra3, 2) * 100)\n",
    "    dst_mrr = int(round(dst_mrr, 2) * 100)\n",
    "\n",
    "    ra3_stdv = str(round(statistics.stdev(overall_ra3['dst']), 2)).lstrip(\"0\")\n",
    "    mrr_stdv = str(round(statistics.stdev(overall_mrr['dst']), 2)).lstrip(\"0\")\n",
    "\n",
    "    entry += f\" \\\\begin{{tabular}}[c]{{@{{}}l@{{}}}}$.{dst_ra3}_{{{ra3_stdv}}}$\\\\\\\\ $.{dst_mrr}_{{{mrr_stdv}}}$\\end{{tabular}} &\\n\"\n",
    "    # entry += f\" \\\\begin{{tabular}}[c]{{@{{}}l@{{}}}}$\\\\mathbf{{.{dst_ra3}}}_{{{ra3_stdv}}}$\\\\\\\\ $\\\\mathbf{{.{dst_mrr}}}_{{{mrr_stdv}}}$\\end{{tabular}} &\\n\"\n",
    "\n",
    "    gain_entry += f\" \\\\begin{{tabular}}[c]{{@{{}}l@{{}}}}${ra3_gain_react}\\\\%$\\\\\\\\ ${mrr_gain_react}\\\\%$\\end{{tabular}} &\\n\"\n",
    "\n",
    "print(entry)\n",
    "print(f\"Improv. over REACT - Min={min(ra3_gains_react)}-R@3, {min(mrr_gains_react)}-MRR | Max={max(ra3_gains_react)}-R@3, {max(mrr_gains_react)}-MRR | Avg={statistics.mean(ra3_gains_react)}-R@3, {statistics.mean(mrr_gains_react)}-MRR\")\n",
    "print(f\"Improv. over no EF - Min={min(ra3_gains_noef)}-R@3, {min(mrr_gains_noef)}-MRR | Max={max(ra3_gains_noef)}-R@3, {max(mrr_gains_noef)}-MRR\")\n",
    "print()\n",
    "print(gain_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
